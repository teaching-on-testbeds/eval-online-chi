{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate and monitor a model online\n",
    "\n",
    "In addition to an offline evaluation, we also need to evaluate and monitor the ML system online, when it is â€œliveâ€ and accepting requests on â€œproduction dataâ€.\n",
    "\n",
    "In this section, we will practice online evaluation of a model! After you finish this section, you should understand how to:\n",
    "\n",
    "-   monitor operational metrics in a live service\n",
    "-   monitor model predictions in a live service\n",
    "-   monitor drift in a live service\n",
    "\n",
    "(In a separate experiment, weâ€™ll practice â€œclosing the feedback loop,â€ and try online evaluation of models with human feedback.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs in jupyter container on node-eval-online-online\n",
    "import os, base64, time, random, requests\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor operational metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To monitor a service using Prometheus, it needs to expose an HTTP endpoint (by convention, `/metrics`) that Prometheus can scrape. For standard frameworks like Flask or FastAPI (or Triton inference server, for that matter) it is easy to use existing libraries to quickly instrument a service.\n",
    "\n",
    "We have already started an updated FastAPI service, which looks very similar to one weâ€™ve developed previously, but now:\n",
    "\n",
    "-   in `requirements.txt`, weâ€™ve added the `prometheus-fastapi-instrumentator` library as a dependency\n",
    "-   and inside the app itself, weâ€™ve added this to the beginning:\n",
    "\n",
    "``` python\n",
    "from prometheus_fastapi_instrumentator import Instrumentator\n",
    "```\n",
    "\n",
    "-   and this to the end:\n",
    "\n",
    "``` python\n",
    "Instrumentator().instrument(app).expose(app)\n",
    "```\n",
    "\n",
    "Meanwhile, we have configured our Prometheus service to get metrics from this service every 15 seconds, in `prometheus.yml`:\n",
    "\n",
    "    global:\n",
    "      scrape_interval: 15s\n",
    "\n",
    "    scrape_configs:\n",
    "      - job_name: 'food11'\n",
    "        static_configs:\n",
    "          - targets: ['fastapi_server:8000']\n",
    "\n",
    "Thatâ€™s all it takes to start sharing the basic operational metrics of a FastAPI service!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we visit\n",
    "\n",
    "    http://A.B.C.D:8000/docs\n",
    "\n",
    "in a browser, but using the floating IP assigned to our instance in place of `A.B.C.D`, weâ€™ll note that in addition to a `/predict` endpoint, our FastAPI service now has a `/metrics` endpoint. This is the endpoint that will be scraped by Prometheus.\n",
    "\n",
    "Click on â€œ/metricsâ€, then â€œTry it outâ€ and â€œExecuteâ€ to see what it returns.\n",
    "\n",
    "Before we look at the actual metrics in Prometheus, letâ€™s generate some data from operational use.\n",
    "\n",
    "In a browser, weâ€™ll visit\n",
    "\n",
    "    http://A.B.C.D:5000\n",
    "\n",
    "but using the floating IP assigned to our instance in place of `A.B.C.D`. Then, upload a few images to the web app and submit them for classification.\n",
    "\n",
    "Now (or, within 15 seconds!) we can look up some operational metrics related to those queries in Prometheus.\n",
    "\n",
    "In a browser, weâ€™ll visit\n",
    "\n",
    "    http://A.B.C.D:9090\n",
    "\n",
    "but using the floating IP assigned to our instance in place of `A.B.C.D`. This will open the Prometheus web UI.\n",
    "\n",
    "First, letâ€™s find out about the services that this Prometheus instance is monitoring. From the menu, choose â€œStatusâ€ \\> â€œTargetsâ€ and note the FastAPI endpoint and its status.\n",
    "\n",
    "Next, letâ€™s look at some of the metrics data. Prometheus uses a query language called PromQL to query metrics, but we can find some metrics of interest without knowing any PromQL. From the menu, choose â€œGraphâ€. Then, click on the globe icon ğŸŒ near the query bar to see some of the available metrics we can query. Find â€œhttp_requests_totalâ€ in the list and click on it to select it, and click â€œExecuteâ€.\n",
    "\n",
    "Prometheus will show us metrics related to all endpoints of the FastAPI service, but we are primarily interested in the metrics associated with the â€œ/predictâ€ endpoint. Copy the line\n",
    "\n",
    "    http_requests_total{handler=\"/predict\", instance=\"fastapi_server:8000\", job=\"food11\", method=\"POST\", status=\"2xx\"}\n",
    "\n",
    "and paste *that* into the query bar. Hit Execute.\n",
    "\n",
    "Switch from the â€œTableâ€ tab to the â€œGraphâ€ tab to see a visualization of the cumulative number of requests served by this endpoint. Revisit the GourmetGram app again, and upload a few more images for classification; then execute the query in Prometheus again (or, after 15 seconds!) and confirm that it is incremented accordingly.\n",
    "\n",
    "Instead of getting the cumulative count of requests, we may prefer to see the rate of requests per second. Put\n",
    "\n",
    "    rate(http_requests_total{handler=\"/predict\", instance=\"fastapi_server:8000\", job=\"food11\", method=\"POST\", status=\"2xx\"}[1m])\n",
    "\n",
    "into the query bar and click â€œExecuteâ€ to see the rate of requests per second, averaged over a 1 minute moving window. You can use the + and - buttons to adjust the range of the horizontal axis to the time interval for which you have measurements.\n",
    "\n",
    "To see more, letâ€™s generate some more requests. Weâ€™ll send some requests directly from this notebook to the FastAPI service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs in jupyter container on node-eval-online-online\n",
    "image_path = \"test_image.jpeg\"\n",
    "with open(image_path, 'rb') as f:\n",
    "    image_bytes = f.read()\n",
    "encoded_str =  base64.b64encode(image_bytes).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs in jupyter container on node-eval-online\n",
    "FASTAPI_URL = \"http://fastapi_server:8000/predict\"\n",
    "payload = {\"image\": encoded_str}\n",
    "num_requests = 100\n",
    "\n",
    "for _ in range(num_requests):\n",
    "    response = requests.post(FASTAPI_URL, json=payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have generated some data that we can query, letâ€™s use Prometheus to understand how long it takes our inference endpoint to serve requests.\n",
    "\n",
    "Request durations are reported as histograms, which is a slightly more involved metric type. Use the query:\n",
    "\n",
    "    rate(http_request_duration_seconds_sum{handler=\"/predict\", job=\"food11\"}[1m]) / \n",
    "    rate(http_request_duration_seconds_count{handler=\"/predict\", job=\"food11\"}[1m])\n",
    "\n",
    "to see the average duration of HTTP requests averaged over a 1 minute window.\n",
    "\n",
    "Averages can be skewed, though - so letâ€™s also look at the median, using the query:\n",
    "\n",
    "    histogram_quantile(0.5, rate(http_request_duration_seconds_bucket{handler=\"/predict\", job=\"food11\"}[1m]))\n",
    "\n",
    "or, to get a sense of the worst-case user experience, we can check the 95th percentile using the query:\n",
    "\n",
    "    histogram_quantile(0.5, rate(http_request_duration_seconds_bucket{handler=\"/predict\", job=\"food11\"}[1m]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ongoing monitoring, we can create a dashboard using Grafana. In a browser, weâ€™ll visit\n",
    "\n",
    "    http://A.B.C.D:3000\n",
    "\n",
    "but using the floating IP assigned to our instance in place of `A.B.C.D`. This will open the Grafana web UI.\n",
    "\n",
    "Sign in using the username `admin` and password `admin`. You will be prompted to change the initial password.\n",
    "\n",
    "Then, youâ€™ll configure it to connect to Prometheus:\n",
    "\n",
    "-   From the menu, choose: â€œConnectionsâ€ \\> â€œData Sourcesâ€.\n",
    "-   Click â€œAdd data sourceâ€ and choose â€œPrometheusâ€.\n",
    "-   Set URL to http://prometheus:9090.\n",
    "-   Click â€œSave & Testâ€\n",
    "\n",
    "Next, weâ€™re going to build a dashboard!\n",
    "\n",
    "-   Click â€œDashboardsâ€ \\> â€œCreate dashboardâ€ and â€œAdd visualizationâ€.\n",
    "-   Select your Prometheus data source.\n",
    "-   Near the bottom, you will see the query builder for your Prometheus data source. Click the â€œCodeâ€ button to toggle from â€œbuilder modeâ€ to â€œcode (PromQL) modeâ€.\n",
    "-   Put the following query in the box and then click â€œRun queriesâ€:\n",
    "\n",
    "<!-- -->\n",
    "\n",
    "    1000 * rate(http_request_duration_seconds_sum{handler=\"/predict\", job=\"food11\"}[1m]) / \n",
    "    rate(http_request_duration_seconds_count{handler=\"/predict\", job=\"food11\"}[1m])\n",
    "\n",
    "-   At the top of the graph, adjust the visible time range to 15 minutes, so that you can see the data\n",
    "-   On the right side, change the panel options: Set title to â€œFood11 average request duration (ms)â€\n",
    "-   When you are satisfied with the appearance, click â€œSave dashboardâ€ and give your dashboard the title â€œFood11 Service Monitoringâ€\n",
    "\n",
    "Now, you can click on â€œDashboardsâ€ \\> â€œFood11 Service Monitoringâ€ to see your dashboard.\n",
    "\n",
    "Letâ€™s add another panel, showing the median, 95th percentile, and 99th percentile request duration.\n",
    "\n",
    "-   Open the dashboard, and click â€œEditâ€ in the top right. Then click â€œAddâ€ \\> â€œVisualizationâ€.\n",
    "-   In the query editor, paste this query and â€œRun queriesâ€:\n",
    "\n",
    "<!-- -->\n",
    "\n",
    "    1000*histogram_quantile(0.5, rate(http_request_duration_seconds_bucket{handler=\"/predict\"}[1m]))\n",
    "\n",
    "-   Then, click â€œAdd queryâ€ and repeat for this query:\n",
    "\n",
    "<!-- -->\n",
    "\n",
    "    1000*histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{handler=\"/predict\"}[1m]))\n",
    "\n",
    "-   Finally, click â€œAdd queryâ€ and add the third query:\n",
    "\n",
    "<!-- -->\n",
    "\n",
    "    1000*histogram_quantile(0.99, rate(http_request_duration_seconds_bucket{handler=\"/predict\"}[1m]))\n",
    "\n",
    "-   Click on â€œLegendâ€ for each query, set it to â€œCustomâ€, and name each series appropriately (e.g.Â â€œMedianâ€, â€œ95th percentileâ€, â€œ99th percentile)\n",
    "-   On the right side, change the panel options: Set title to â€œFood11 request duration percentiles (ms)â€\n",
    "-   At the top of the graph, adjust the visible time range to 15 minutes, so that you can see the data\n",
    "-   When you are satisfied with the appearance, click â€œSave dashboardâ€ to save your changes.\n",
    "\n",
    "Return to the dashboard. You can resize panels and drag them to place them in different positions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the process to add additional panels to your dashboard:\n",
    "\n",
    "-   Requests per second:\n",
    "\n",
    "<!-- -->\n",
    "\n",
    "    rate(http_requests_total{handler=\"/predict\"}[1m])\n",
    "\n",
    "-   and requests that return an error status or fail (this will have â€œno dataâ€ for now). Youâ€™ll add two queries, one for error statuses and one for failed requests:\n",
    "\n",
    "<!-- -->\n",
    "\n",
    "    # set this up as the first query\n",
    "    rate(http_requests_total{handler=\"/predict\", status=\"4xx\"}[1m])\n",
    "\n",
    "    # set this up as a second query in the same visualization\n",
    "    rate(http_requests_total{handler=\"/predict\", status=\"5xx\"}[1m])\n",
    "\n",
    "Now, letâ€™s generate variable load - we will ramp up, then down, the load on the FastAPI service. While the cell below is running, observe the effect on your Grafana dashboard (you can set the dashboard to auto refresh with a frequency of 5 seconds, to make it easier to monitor!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs in jupyter container on node-eval-online\n",
    "FASTAPI_URL = \"http://fastapi_server:8000/predict\"\n",
    "payload = {\"image\": encoded_str}\n",
    "\n",
    "load_pattern = [1, 2, 3, 5, 3, 2, 1]  # number of concurrent requests in each step\n",
    "delay_between_steps = 30 \n",
    "\n",
    "def send_continuous_requests(duration_sec):\n",
    "    start_time = time.time()\n",
    "    while time.time() - start_time < duration_sec:\n",
    "        requests.post(FASTAPI_URL, json=payload, timeout=5)\n",
    "\n",
    "def run_load_stage(concurrent_workers, duration_sec):\n",
    "    with ThreadPoolExecutor(max_workers=concurrent_workers) as executor:\n",
    "        futures = [executor.submit(send_continuous_requests, duration_sec) for _ in range(concurrent_workers)]\n",
    "        for f in futures:\n",
    "            f.result()  # Wait for all threads to finish\n",
    "\n",
    "for load in load_pattern:\n",
    "    run_load_stage(load, delay_between_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it is done, take a screenshot of the â€œFood11 Service Monitoringâ€ dashboard for later reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also generate some error responses, to see them on our dashboard. Visit\n",
    "\n",
    "    http://A.B.C.D:8000/docs\n",
    "\n",
    "in a browser, but using the floating IP assigned to our instance in place of `A.B.C.D`. Click on the â€œpredictâ€ endpoint, and â€œTry it outâ€. Set the request body to\n",
    "\n",
    "    { }\n",
    "\n",
    "and click â€œExecuteâ€. Scroll down to see the server response, which will be\n",
    "\n",
    "-   Code: 422\n",
    "-   Details: Error: Unprocessable Entity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alert on operational metrics\n",
    "\n",
    "Grafana and/or Prometheus can also be configured with alerting - they can email, post a message in Slack, or execute various other notification actions based on operational metrics. As a demo, letâ€™s configure Grafana to alert when there is more than 20 error or failed responses/second for at least 1 minute.\n",
    "\n",
    "On your dashboard, click on the â«¶ in the â€œError responsesâ€ panel, and under â€œMoreâ€, choose â€œNew Alert Ruleâ€.\n",
    "\n",
    "-   In â€œ1. Enter alert rule nameâ€, name it â€œError responsesâ€\n",
    "-   In â€œ2. Define query and alert conditionâ€:\n",
    "    -   Delete the existing â€œCâ€ and â€œDâ€ expressions using the trash icon.\n",
    "    -   Click â€œAdd expressionâ€ \\> â€œReduceâ€. Under â€œExpressionsâ€ \\> â€œC Reduceâ€, choose input A, function Last, and mode Replace non-numeric values with 0.\n",
    "    -   Click â€œAdd expressionâ€ \\> â€œReduceâ€. Under â€œExpressionsâ€ \\> â€œD Reduceâ€, choose input B, function Last, and mode Replace non-numeric values with 0.\n",
    "    -   Click â€œAdd expressionâ€ \\> â€œMathâ€. Under â€œExpressionsâ€ \\> â€œE Mathâ€, use: `$C + $D` to get the sum of the most recent values of A and B\n",
    "    -   Click â€œAdd expressionâ€ \\> â€œThresholdâ€. Under â€œExpressionsâ€ \\> â€œF Thresholdâ€, configure it to alert when input â€œEâ€ (the â€œmathâ€ expression) is above 20. Click â€œSet F as alert conditionâ€.\n",
    "    -   Click â€œPreviewâ€ to verify that no errors are raised.\n",
    "-   In â€œ3. Add folder and labelsâ€, create a new folder named â€œFood11â€\n",
    "-   In â€œ4. Set evaluation behaviorâ€, create a new evaluation group named â€œFood11â€ with a 30s evaluation interval. Set the â€œPending periodâ€ to 1m.\n",
    "-   In â€œ5. Configure notificationsâ€, choose to â€œView or create contact pointsâ€. Since we have not configured this Grafana instance to actually send emails, weâ€™re going to create a â€œNo-opâ€ contact just to observe alerts within Grafana itself. Click â€œCreate contact pointâ€, name it â€œNo-opâ€, select the â€œWebhookâ€ integration, and put â€œhttp://localhost/â€ in the URL field. Save the contact point. Then, on the alert rule setup page, click the refresh icon next to the â€œContact pointâ€ drop-down menu, and choose the â€œNo-opâ€ option\n",
    "-   Click â€œSave rule and exitâ€ in the top right.\n",
    "\n",
    "Now, if you click on â€œAlertingâ€ \\> â€œAlert rulesâ€, you should see a â€œFood11â€ folder with a â€œFood11â€ group inside it, and in it, your rule on â€œError responsesâ€.\n",
    "\n",
    "Letâ€™s generate some error responses to trigger this alert. Weâ€™re executing a similar â€œramp-up/ramp-downâ€ request pattern as before, but sending either\n",
    "\n",
    "-   an empty payload, which we know will make the server return a 422 code\n",
    "-   or an invalid payload, which will make the server return a 500 code\n",
    "\n",
    "(instead of 200, which is a code indicating success)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs in jupyter container on node-eval-online\n",
    "FASTAPI_URL = \"http://fastapi_server:8000/predict\"\n",
    "\n",
    "load_pattern = [1, 3, 5, 10, 5, 3, 1]  # number of concurrent requests in each step\n",
    "delay_between_steps = 30 \n",
    "\n",
    "def send_continuous_requests(duration_sec):\n",
    "    start_time = time.time()\n",
    "    while time.time() - start_time < duration_sec:\n",
    "        payload = random.choice([{}, {\"image\": \"bad data\"}])\n",
    "        requests.post(FASTAPI_URL, json=payload, timeout=5)\n",
    "\n",
    "def run_load_stage(concurrent_workers, duration_sec):\n",
    "    with ThreadPoolExecutor(max_workers=concurrent_workers) as executor:\n",
    "        futures = [executor.submit(send_continuous_requests, duration_sec) for _ in range(concurrent_workers)]\n",
    "        for f in futures:\n",
    "            f.result()  # Wait for all threads to finish\n",
    "\n",
    "for load in load_pattern:\n",
    "    run_load_stage(load, delay_between_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this runs:\n",
    "\n",
    "-   watch the dashboard! You will see visual indicator when the alert is â€œPendingâ€, which means that the threshold for alerting has been met, and it will alert if this condition persists for the entire â€œPending periodâ€ (which we set to 1 minute). You will also see a visual indicator when the alert is â€œFiredâ€, after the condition persists for the â€œPending periodâ€, and another visual indicator when the alert status returns to â€œNormalâ€.\n",
    "-   and, on the â€œAlertingâ€ \\> â€œAlert rulesâ€ page, watch the state of your alert rule and see how it cycles through these states. Although we have not configured email, we can see when an email (or other notification) *would* have been sent - when the alert is â€œFiredâ€.\n",
    "\n",
    "When it is done, take a screenshot of the â€œFood11 Service Monitoringâ€ dashboard for later reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We built this dashboard with â€œClickOpsâ€ but in general, we would want to keep dashboards along with the rest of our infrastructure configuration in version control. Fortunately, dashboard definitions can be exported as JSON files and loaded systematically in a Grafana container.\n",
    "\n",
    "From your dashboard, click â€œExportâ€ \\> â€œExport as JSONâ€, and download the file.\n",
    "\n",
    "This JSON (along with some YAML configuration files) can be used to [provision Grafana](https://grafana.com/docs/grafana/latest/administration/provisioning/), so you can just bring it up (e.g.Â as part of a Docker Compose or a Kubernetes service) and have it ready to go. (We wonâ€™t do this now, though.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor predictions\n",
    "\n",
    "In addition to standard â€œweb serviceâ€ metrics, we may want to monitor application-specific metrics during operation. For example, letâ€™s monitor the confidence of the model in its predictions, and the frequency with which it predicts each class.\n",
    "\n",
    "Weâ€™ll need to make a few changes to our FastAPI service, since the auto-instrumentation of `prometheus-fastapi-instrumentator` does not include application-specific metrics.\n",
    "\n",
    "1.  Add the Prometheus Python client to the `requirements.txt` of the FastAPI container. Run\n",
    "\n",
    "<!-- -->\n",
    "\n",
    "    # runs on node-eval-online\n",
    "    nano eval-online-chi/fastapi_pt/requirements.txt\n",
    "\n",
    "and add `prometheus-client`. Save this file with Ctrl+O and Enter, then quit `nano` with Ctrl+X.\n",
    "\n",
    "1.  Edit `app.py`:\n",
    "\n",
    "<!-- -->\n",
    "\n",
    "    # runs on node-eval-online\n",
    "    nano eval-online-chi/fastapi_pt/app.py\n",
    "\n",
    "Near the top, add\n",
    "\n",
    "``` python\n",
    "from prometheus_client import Histogram, Counter\n",
    "```\n",
    "\n",
    "and then\n",
    "\n",
    "``` python\n",
    "# Histogram for prediction confidence\n",
    "confidence_histogram = Histogram(\n",
    "    \"prediction_confidence\",\n",
    "    \"Model prediction confidence\",\n",
    "    buckets=[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]  \n",
    ")\n",
    "\n",
    "# Count how often we predict each class\n",
    "class_counter = Counter(\n",
    "    \"predicted_class_total\",\n",
    "    \"Count of predictions per class\",\n",
    "    ['class_name']\n",
    ")\n",
    "```\n",
    "\n",
    "Scroll to the â€œRun inferenceâ€ section, and just before the inference result is returned, add\n",
    "\n",
    "``` python\n",
    "        # Update metrics\n",
    "        confidence_histogram.observe(confidence)\n",
    "        class_counter.labels(class_name=classes[predicted_class]).inc()\n",
    "```\n",
    "\n",
    "to observe the confidence value, and increment the class counter for the corresponding class.\n",
    "\n",
    "Save this file with Ctrl+O and Enter, then quit `nano` with Ctrl+X.\n",
    "\n",
    "Re-build the container image with\n",
    "\n",
    "``` bash\n",
    "# runs on node-eval-online\n",
    "docker compose -f eval-online-chi/docker/docker-compose-prometheus.yaml build fastapi_server\n",
    "```\n",
    "\n",
    "and then recreate it with\n",
    "\n",
    "``` bash\n",
    "# runs on node-eval-online\n",
    "docker compose -f eval-online-chi/docker/docker-compose-prometheus.yaml up -d\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Letâ€™s test it! In a browser, weâ€™ll visit\n",
    "\n",
    "    http://A.B.C.D:5000\n",
    "\n",
    "but using the floating IP assigned to our instance in place of `A.B.C.D`. Then, upload a few images to the web app and submit them for classification.\n",
    "\n",
    "Next, open\n",
    "\n",
    "    http://A.B.C.D:8000/docs\n",
    "\n",
    "in a browser, but using the floating IP assigned to our instance. Click on â€œ/metricsâ€, then â€œTry it outâ€ and â€œExecuteâ€. Note that now, the reported metrics include `prediction_confidence_bucket` for each bucket, and `predicted_class_total` for each class.\n",
    "\n",
    "Weâ€™ll add another dashboard to Grafana to monitor the predictions. Instead of the â€œClickOpsâ€ way, weâ€™ll set up this dashboard by importing it from a JSON definition.\n",
    "\n",
    "In Grafana, click â€œDashboardsâ€ \\> â€œNewâ€ \\> â€œImportâ€ and where it says â€œImport via dashboard JSON modelâ€, paste:\n",
    "\n",
    "    {\n",
    "      \"id\": null,\n",
    "      \"title\": \"Food11 Prediction Monitoring\",\n",
    "      \"timezone\": \"browser\",\n",
    "      \"time\": {\n",
    "        \"from\": \"now-15m\",\n",
    "        \"to\": \"now\"\n",
    "      },\n",
    "      \"refresh\": \"5s\",\n",
    "      \"schemaVersion\": 38,\n",
    "      \"version\": 1,\n",
    "      \"panels\": [\n",
    "        {\n",
    "          \"type\": \"timeseries\",\n",
    "          \"title\": \"Average Prediction Confidence\",\n",
    "          \"gridPos\": { \"x\": 0, \"y\": 0, \"w\": 12, \"h\": 8 },\n",
    "          \"targets\": [\n",
    "            {\n",
    "              \"expr\": \"sum(rate(prediction_confidence_sum[1m])) / sum(rate(prediction_confidence_count[1m]))\",\n",
    "              \"legendFormat\": \"avg(confidence)\",\n",
    "              \"refId\": \"A\"\n",
    "            }\n",
    "          ],\n",
    "          \"fieldConfig\": {\n",
    "            \"defaults\": {\n",
    "              \"unit\": \"percentunit\",\n",
    "              \"min\": 0,\n",
    "              \"max\": 1\n",
    "            }\n",
    "          },\n",
    "          \"options\": {\n",
    "            \"legend\": {\n",
    "              \"displayMode\": \"list\",\n",
    "              \"placement\": \"bottom\"\n",
    "            },\n",
    "            \"tooltip\": {\n",
    "              \"mode\": \"single\"\n",
    "            }\n",
    "          },\n",
    "          \"datasource\": \"prometheus\"\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"timeseries\",\n",
    "          \"title\": \"Prediction Confidence (Cumulative)\",\n",
    "          \"gridPos\": { \"x\": 12, \"y\": 0, \"w\": 12, \"h\": 8 },\n",
    "          \"targets\": [\n",
    "            {\n",
    "              \"expr\": \"rate(prediction_confidence_bucket{le!=\\\"+Inf\\\"}[1m])\",\n",
    "              \"legendFormat\": \"{{le}}\",\n",
    "              \"refId\": \"A\"\n",
    "            }\n",
    "          ],\n",
    "          \"fieldConfig\": {\n",
    "            \"defaults\": {\n",
    "              \"unit\": \"ops\",\n",
    "              \"custom\": {\n",
    "                \"fillOpacity\": 80,\n",
    "                \"stacking\": {\n",
    "                  \"mode\": \"normal\"\n",
    "                }\n",
    "              }\n",
    "            },\n",
    "            \"overrides\": []\n",
    "          },\n",
    "          \"options\": {\n",
    "            \"legend\": {\n",
    "              \"displayMode\": \"list\",\n",
    "              \"placement\": \"bottom\"\n",
    "            },\n",
    "            \"tooltip\": {\n",
    "              \"mode\": \"single\"\n",
    "            }\n",
    "          },\n",
    "          \"datasource\": \"prometheus\"\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"bargauge\",\n",
    "          \"title\": \"Prediction Confidence (Over Selected Time Range)\",\n",
    "          \"gridPos\": { \"x\": 0, \"y\": 8, \"w\": 12, \"h\": 10 },\n",
    "          \"targets\": [\n",
    "            {\n",
    "              \"expr\": \"increase(prediction_confidence_bucket{le!=\\\"+Inf\\\"}[$__range])\",\n",
    "              \"legendFormat\": \"â‰¤ {{le}}\",\n",
    "              \"refId\": \"A\"\n",
    "            }\n",
    "          ],\n",
    "          \"options\": {\n",
    "            \"orientation\": \"horizontal\",\n",
    "            \"displayMode\": \"gradient\",\n",
    "            \"showUnfilled\": true\n",
    "          },\n",
    "          \"fieldConfig\": {\n",
    "            \"defaults\": {\n",
    "              \"unit\": \"short\",\n",
    "              \"min\": 0\n",
    "            }\n",
    "          },\n",
    "          \"datasource\": \"prometheus\"\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"bargauge\",\n",
    "          \"title\": \"Predicted Class Totals (Over Selected Time Range)\",\n",
    "          \"gridPos\": { \"x\": 12, \"y\": 8, \"w\": 12, \"h\": 10 },\n",
    "          \"targets\": [\n",
    "            {\n",
    "              \"expr\": \"increase(predicted_class_total[$__range])\",\n",
    "              \"legendFormat\": \"{{class_name}}\",\n",
    "              \"refId\": \"A\"\n",
    "            }\n",
    "          ],\n",
    "          \"options\": {\n",
    "            \"orientation\": \"horizontal\",\n",
    "            \"displayMode\": \"gradient\",\n",
    "            \"showUnfilled\": true\n",
    "          },\n",
    "          \"fieldConfig\": {\n",
    "            \"defaults\": {\n",
    "              \"unit\": \"short\",\n",
    "              \"min\": 0\n",
    "            }\n",
    "          },\n",
    "          \"datasource\": \"prometheus\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "\n",
    "then click â€œLoadâ€ and â€œImportâ€. Now, you have a â€œFood11 Prediction Monitoringâ€ dashboard in addition to your â€œFood11 Serviceâ€ dashboard.\n",
    "\n",
    "Letâ€™s generate some requests to populate this dashboard with meaningful data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs in jupyter container on node-eval-online\n",
    "food_11_data_dir = os.getenv(\"FOOD11_DATA_DIR\", \"Food-11\")\n",
    "test_dataset = datasets.ImageFolder(root=os.path.join(food_11_data_dir, 'evaluation'))\n",
    "image_paths = [sample[0] for sample in test_dataset.samples]\n",
    "random.shuffle(image_paths)\n",
    "\n",
    "FASTAPI_URL = \"http://fastapi_server:8000/predict\"\n",
    "\n",
    "for image_path in image_paths:\n",
    "    with open(image_path, 'rb') as f:\n",
    "        image_bytes = f.read()\n",
    "    encoded_str = base64.b64encode(image_bytes).decode(\"utf-8\")\n",
    "    payload = {\"image\": encoded_str}\n",
    "    response = requests.post(FASTAPI_URL, json=payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it is done, take a screenshot of the â€œFood11 Prediction Monitoringâ€ dashboard for later reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alert on prediction metrics\n",
    "\n",
    "With this dashboard, we can monitor how the predicted class distribution and prediction confidence is evolving. For example, if our model is becoming â€œstaleâ€ and has less confidence in its predictions, we can use that to trigger an alert and potentially, re-train the model.\n",
    "\n",
    "Weâ€™ll try it now - on the dashboard, click on the â«¶ in the â€œAverage Prediction Confidenceâ€ panel, and under â€œMoreâ€, choose â€œNew Alert Ruleâ€.\n",
    "\n",
    "-   In â€œ1. Enter alert rule nameâ€, name it â€œLow prediction confidenceâ€\n",
    "-   In â€œ2. Define query and alert conditionâ€, set the Alert Condition to: When query is below 0.75\n",
    "-   In â€œ3. Add folder and labelsâ€, use â€œFood11â€\n",
    "-   In â€œ4. Set evaluation behaviorâ€, use the evaluation group named â€œFood11â€. Set the â€œPending periodâ€ to 1m. (In a real production setting, we would want this alert to fire only if prediction confidence is low for an extended period of time, like hours, days, or weeks, but in this example we use a small pending period so that we can see it in a shorter time frame!)\n",
    "-   In â€œ5. Configure notificationsâ€, use the â€œNo-Opâ€ notification option. (In a real production service, we might configure a notification to a webhook that would trigger rebuilding, for example.)\n",
    "-   Click â€œSave rule and exitâ€ in the top right.\n",
    "\n",
    "Repeat the cell above this one to send requests for the test dataset. This will not trigger the alert, since the prediction confidence is high.\n",
    "\n",
    "Immediately after that, run the cell below, to send prediction requests for the â€œcake_looks_likeâ€ samples (of photos of cake that look like other food items), where the prediction confidence will be lower:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs in jupyter container on node-eval-online\n",
    "image_dir = \"cake_looks_like\"\n",
    "image_paths = [\n",
    "    os.path.join(image_dir, fname)\n",
    "    for fname in os.listdir(image_dir)\n",
    "    if fname.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
    "]\n",
    "\n",
    "FASTAPI_URL = \"http://fastapi_server:8000/predict\"\n",
    "\n",
    "for _ in range(1000):\n",
    "    random.shuffle(image_paths)\n",
    "    for image_path in image_paths:\n",
    "        with open(image_path, 'rb') as f:\n",
    "            image_bytes = f.read()\n",
    "        encoded_str = base64.b64encode(image_bytes).decode(\"utf-8\")\n",
    "        payload = {\"image\": encoded_str}\n",
    "        response = requests.post(FASTAPI_URL, json=payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a screenshot of this â€œFood11 Prediction Monitoringâ€ dashboard showing where the alert condition is triggered and where it is fired."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor infrastructure metrics\n",
    "\n",
    "Finally, we should also monitor the containers themselves. Weâ€™ll use [`cAdvisor`](https://github.com/google/cadvisor).\n",
    "\n",
    "1.  First, add a `cadvisor` container to the Docker Compose YAML. Open it with\n",
    "\n",
    "``` bash\n",
    "# runs on node-eval-online\n",
    "nano eval-online-chi/docker/docker-compose-prometheus.yaml\n",
    "```\n",
    "\n",
    "then add this to the end of the `services` section (before the `volumes` section):\n",
    "\n",
    "      cadvisor:\n",
    "        image: gcr.io/cadvisor/cadvisor:latest\n",
    "        container_name: cadvisor\n",
    "        ports:\n",
    "          - \"8080:8080\"\n",
    "        volumes:\n",
    "          - /:/rootfs:ro\n",
    "          - /var/run:/var/run:ro\n",
    "          - /sys:/sys:ro\n",
    "          - /var/lib/docker/:/var/lib/docker:ro\n",
    "        restart: unless-stopped\n",
    "\n",
    "Save the file with Ctrl+O and Enter, then Ctrl+X to exit.\n",
    "\n",
    "1.  Tell Prometheus to scrape this endpoint for metrics. Open the Prometheus config with\n",
    "\n",
    "``` bash\n",
    "# runs on node-eval-online\n",
    "nano eval-online-chi/docker/prometheus.yml\n",
    "```\n",
    "\n",
    "and at the end, in the `scrape_configs` section, add:\n",
    "\n",
    "      - job_name: 'cadvisor'\n",
    "        static_configs:\n",
    "          - targets: ['cadvisor:8080']\n",
    "\n",
    "Save the file with Ctrl+O and Enter, then Ctrl+X to exit.\n",
    "\n",
    "1.  Bring up the new container with\n",
    "\n",
    "``` bash\n",
    "# runs on node-eval-online\n",
    "docker compose -f eval-online-chi/docker/docker-compose-prometheus.yaml up -d\n",
    "```\n",
    "\n",
    "and force the Prometheus container to restart with its new configuration:\n",
    "\n",
    "``` bash\n",
    "# runs on node-eval-online\n",
    "docker compose -f eval-online-chi/docker/docker-compose-prometheus.yaml up prometheus --force-recreate -d\n",
    "```\n",
    "\n",
    "**Note**: `cAdvisor` has its own web UI. You can see it at\n",
    "\n",
    "    http://A.B.C.D:8080\n",
    "\n",
    "in a browser, but using the floating IP assigned to our instance in place of `A.B.C.D`. Click on â€œDocker containersâ€ and then any individual container to see more details of its resource usage.\n",
    "\n",
    "1.  Then, weâ€™ll import a [pre-built Grafana dashboard for cAdvisor](https://grafana.com/grafana/dashboards/19908-docker-container-monitoring-with-prometheus-and-cadvisor/).\n",
    "\n",
    "-   In Grafana, click â€œDashboardsâ€ \\> â€œNewâ€ \\> â€œImportâ€\n",
    "-   Enter this URL in the space where it says â€œFind and import dashboards for common applications at grafana.com/dashboardsâ€:\n",
    "\n",
    "<!-- -->\n",
    "\n",
    "    https://grafana.com/grafana/dashboards/19908-docker-container-monitoring-with-prometheus-and-cadvisor/\n",
    "\n",
    "-   Click â€œLoadâ€.\n",
    "-   In the â€œPrometheusâ€ section, use the drop-down menu to select your Prometheus data source.\n",
    "-   Then, click â€œImportâ€.\n",
    "\n",
    "Now, youâ€™ll see the â€œcAdvisor Docker Insightsâ€ dashboard in the â€œDashboardsâ€ section. Open the dashboard and monitor the resource usage of your Docker containers when you generate requests against the FastAPI service. (Adjust the time scale of the dashboard to 15 minutes so that you can see the data.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs in jupyter container on node-eval-online\n",
    "FASTAPI_URL = \"http://fastapi_server:8000/predict\"\n",
    "payload = {\"image\": encoded_str}\n",
    "\n",
    "load_pattern = [1, 2, 3, 5, 3, 2, 1]  # number of concurrent requests in each step\n",
    "delay_between_steps = 60 \n",
    "\n",
    "def send_continuous_requests(duration_sec):\n",
    "    start_time = time.time()\n",
    "    while time.time() - start_time < duration_sec:\n",
    "        requests.post(FASTAPI_URL, json=payload, timeout=5)\n",
    "\n",
    "def run_load_stage(concurrent_workers, duration_sec):\n",
    "    with ThreadPoolExecutor(max_workers=concurrent_workers) as executor:\n",
    "        futures = [executor.submit(send_continuous_requests, duration_sec) for _ in range(concurrent_workers)]\n",
    "        for f in futures:\n",
    "            f.result()  # Wait for all threads to finish\n",
    "\n",
    "for load in load_pattern:\n",
    "    run_load_stage(load, delay_between_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let this run for about ten minutes. Then, come back a few minutes later (because in this dashboard, rate metrics are over a 10 minute window) and take a screenshot of the â€œcAdvisor Docker Insightsâ€ dashboard for later reference. (You donâ€™t have to capture the entire dashboard, itâ€™s fine if itâ€™s just the top panels.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect data drift\n",
    "\n",
    "For machine learning systems in particular, it is important to monitor for data drift - when new production data is dissimilar to the data on which a model was trained.\n",
    "\n",
    "There are many different tests for data drift, depending on what type of data you are working with (tabular, image, text, audio, time series). In this example, we will use the [`alibi-detect`](https://github.com/SeldonIO/alibi-detect) package, which implements many of these tests. Hereâ€™s the current list of drift detection tests that are implemented:\n",
    "\n",
    "| Detector                         | Tabular | Image | Time Series | Text | Categorical Features | Online | Feature Level |\n",
    "|:--------------------------------|:----:|:----:|:----:|:----:|:----:|:----:|:----:|\n",
    "| Kolmogorov-Smirnov               |    âœ”    |   âœ”   |             |  âœ”   |          âœ”           |        |       âœ”       |\n",
    "| CramÃ©r-von Mises                 |    âœ”    |   âœ”   |             |      |                      |   âœ”    |       âœ”       |\n",
    "| Fisherâ€™s Exact Test              |    âœ”    |       |             |      |          âœ”           |   âœ”    |       âœ”       |\n",
    "| Maximum Mean Discrepancy (MMD)   |    âœ”    |   âœ”   |             |  âœ”   |          âœ”           |   âœ”    |               |\n",
    "| Learned Kernel MMD               |    âœ”    |   âœ”   |             |  âœ”   |          âœ”           |        |               |\n",
    "| Context-aware MMD                |    âœ”    |   âœ”   |      âœ”      |  âœ”   |          âœ”           |        |               |\n",
    "| Least-Squares Density Difference |    âœ”    |   âœ”   |             |  âœ”   |          âœ”           |   âœ”    |               |\n",
    "| Chi-Squared                      |    âœ”    |       |             |      |          âœ”           |        |       âœ”       |\n",
    "| Mixed-type tabular data          |    âœ”    |       |             |      |          âœ”           |        |       âœ”       |\n",
    "| Classifier                       |    âœ”    |   âœ”   |      âœ”      |  âœ”   |          âœ”           |        |               |\n",
    "| Spot-the-diff                    |    âœ”    |   âœ”   |      âœ”      |  âœ”   |          âœ”           |        |       âœ”       |\n",
    "| Classifier Uncertainty           |    âœ”    |   âœ”   |      âœ”      |  âœ”   |          âœ”           |        |               |\n",
    "| Regressor Uncertainty            |    âœ”    |   âœ”   |      âœ”      |  âœ”   |          âœ”           |        |               |\n",
    "\n",
    "We will consider a specific measure of drift called Maximum Mean Discrepenacy (MMD). This â€œdetectorâ€ will look at the data before the final classification decision - in this case, where we have used transfer learning to fit a classification head on top of a â€œbaseâ€ model, weâ€™ll look at the output of the â€œbaseâ€ model. Then, MMD will compute the distance between the mean embeddings of the features from:\n",
    "\n",
    "-   the distribution of some â€œreferenceâ€ data\n",
    "-   and the distribution of new samples\n",
    "\n",
    "to see how different they are.\n",
    "\n",
    "Letâ€™s try this now. First, we will grab a batch of the training data to use as the â€œreferenceâ€ data, and a sample of validation data to use as â€œnewâ€ data -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs in jupyter container on node-eval-online\n",
    "model_path = \"models/food11.pth\"  \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = torch.load(model_path, map_location=device, weights_only=False)\n",
    "_ = model.eval()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs in jupyter container on node-eval-online\n",
    "food_11_data_dir = os.getenv(\"FOOD11_DATA_DIR\", \"Food-11\")\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=os.path.join(food_11_data_dir, 'training'), transform=val_test_transform)\n",
    "train_loader  = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "val_dataset   = datasets.ImageFolder(root=os.path.join(food_11_data_dir, 'validation'), transform=val_test_transform)\n",
    "val_loader    = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs in jupyter container on node-eval-online\n",
    "x_ref, y_ref = next(iter(train_loader))\n",
    "print(\"x_ref shape:\", x_ref.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs in jupyter container on node-eval-online\n",
    "x_new, y_new = next(iter(val_loader))\n",
    "print(\"x_new shape:\", x_new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will set up our drift detector.\n",
    "\n",
    "-   we will prepare a `feature_model` that gets the feature map from our model, before the classification haed\n",
    "-   its output will be passed to a preprocessing function\n",
    "-   and then, pass the reference data to MMD-based change detector using the reference data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs in jupyter container on node-eval-online\n",
    "from alibi_detect.cd.pytorch import HiddenOutput, preprocess_drift\n",
    "from alibi_detect.cd import MMDDrift, MMDDriftOnline\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs in jupyter container on node-eval-online\n",
    "\n",
    "# Use `HiddenOutput` from alibi_detect to extract features from the last layer of our classifier before the \"head\"\n",
    "feature_model = HiddenOutput(model, layer=-1) \n",
    "\n",
    "# preprocess_drift defines the model used for drift detection - the HiddenOutput model\n",
    "preprocess_fn = partial(preprocess_drift, model=feature_model, batch_size=128)\n",
    "\n",
    "# Create an MMD-based change detector, where:\n",
    "#  - x_ref is reference data to describe what input to the classifier head *should* look like\n",
    "#  - preprocess_fn will be used to extract features from both reference and test data,\n",
    "#  - the backend is PyTorch (Tensorflow is also supported)\n",
    "#  - p_val = 0.05 means we consider the difference between reference and test data to be significant at 95% confidence\n",
    "cd = MMDDrift(x_ref, backend='pytorch', p_val=.05, preprocess_fn=preprocess_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get another batch of training data, and pass it to the detector -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs in jupyter container on node-eval-online\n",
    "x_tr, y_tr = next(iter(train_loader))\n",
    "cd_preds = cd.predict(x_tr)\n",
    "cd_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should show that no drift was detected (`is_drift`: `0`) because the p-value is higher than the threshold we set for statistical significance (`0.05`), and the `distance` between test and reference distributions is small - well below the `distance_threshold`. This means that this batch of data is statistically similar to the reference data.\n",
    "\n",
    "To use this drift detector in production, weâ€™ll need the online version of it, which accepts one sample at a time as input instead of a batch of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs in jupyter container on node-eval-online\n",
    "preprocess_fn = partial(preprocess_drift, model=feature_model)\n",
    "\n",
    "cd_online = MMDDriftOnline(\n",
    "    x_ref,           # reference embeddings\n",
    "    ert=300,         # expected run time between false positives (larger = fewer false alarms)\n",
    "    window_size=10,  # how many test samples to use in each MMD check\n",
    "    backend='pytorch',\n",
    "    preprocess_fn=preprocess_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs in jupyter container on node-eval-online\n",
    "# try the online detector on evaluation data\n",
    "results = []\n",
    "x_new, y_new = next(iter(val_loader))  # one batch\n",
    "for x in x_new:\n",
    "    cd_pred = cd_online.predict(x.cpu().numpy())\n",
    "    results.append(cd_pred['data'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs in jupyter container on node-eval-online\n",
    "print([r['is_drift'] for r in results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(ignore the first `window_size` outputs, which are not meaningful.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if there are genuinely different images than the ones seen in training? Suppose that more GourmetGram users are submitting AI-generated images, which are very different from the images seen in training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs in jupyter container on node-eval-online\n",
    "image_dir = \"ai_images\"\n",
    "image_files = [\n",
    "    f for f in os.listdir(image_dir)\n",
    "    if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))\n",
    "]\n",
    "\n",
    "num_images = 16\n",
    "sample_files = random.sample(image_files, min(num_images, len(image_files)))\n",
    "\n",
    "cols = 4\n",
    "rows = (len(sample_files) + cols - 1) // cols\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(12, 12))\n",
    "\n",
    "for ax, filename in zip(axes.flatten(), sample_files):\n",
    "    image_path = os.path.join(image_dir, filename)\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(filename, fontsize=10)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs in jupyter container on node-eval-online\n",
    "# try the online detector on AI-generated image data\n",
    "results_ai = []\n",
    "sample_files = random.sample(image_files, min(32, len(image_files)))\n",
    "for filename in sample_files:\n",
    "    image_path = os.path.join(image_dir, filename)\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    x_tensor = val_test_transform(image)  # shape: [3, 224, 224]\n",
    "    x_np = x_tensor.numpy()\n",
    "    cd_pred = cd_online.predict(x_np)\n",
    "    results_ai.append(cd_pred['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs in jupyter container on node-eval-online\n",
    "print([r['is_drift'] for r in results_ai])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_stats = [r['test_stat'] for r in results[:32]]\n",
    "drift_flags = [r['is_drift'] for r in results[:32]]\n",
    "\n",
    "test_stats_ai = [r['test_stat'] for r in results_ai[:32]]\n",
    "drift_flags_ai = [r['is_drift'] for r in results_ai[:32]]\n",
    "\n",
    "combined_stats = test_stats + test_stats_ai\n",
    "combined_flags = drift_flags + drift_flags_ai\n",
    "combined_labels = ['regular'] * len(test_stats) + ['ai'] * len(test_stats_ai)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i, (stat, drift, label) in enumerate(zip(combined_stats, combined_flags, combined_labels)):\n",
    "    color = 'red' if drift else 'blue'\n",
    "    marker = 'o' if label == 'regular' else 's'\n",
    "    plt.scatter(i, stat, color=color, marker=marker)\n",
    "\n",
    "threshold = results[0]['threshold'] if results else results_ai[0]['threshold']\n",
    "plt.axhline(y=threshold, linestyle='--', color='gray')\n",
    "\n",
    "plt.title(\"Drift Detection\")\n",
    "plt.xlabel(\"Sample Index\")\n",
    "plt.ylabel(\"Test statistic\")\n",
    "plt.legend(handles=[\n",
    "    plt.Line2D([0], [0], marker='o', color='w', label='Food11 samples', markerfacecolor='blue'),\n",
    "    plt.Line2D([0], [0], marker='s', color='w', label='AI samples', markerfacecolor='red'),\n",
    "    plt.Line2D([0], [0], color='gray', linestyle='--', label='threshold')\n",
    "])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The drift detector should identify that the samples in the â€œai_imagesâ€ set are diferent from those in the Food11 validation set. (Some samples are more â€œlikeâ€ Food11 than others - you can run this multiple times to try again with different random samples.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor for data drift\n",
    "\n",
    "Letâ€™s integrate this into our prediction endpoint, so that drift metrics from production data will be generally available - e.g.Â for things like deciding when to retrain the model.\n",
    "\n",
    "First, we need to save the change detection model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs in jupyter container on node-eval-online\n",
    "from alibi_detect.saving import save_detector\n",
    "cd_online.reset_state()\n",
    "save_detector(cd_online, \"cd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to modify our FastAPI service!\n",
    "\n",
    "1.  Copy the saved change detector to our FastAPI service directory.\n",
    "\n",
    "``` bash\n",
    "# runs on node-eval-online\n",
    "cp -R eval-online-chi/workspace/cd eval-online-chi/fastapi_pt/\n",
    "```\n",
    "\n",
    "1.  Open the FastAPI `app.py` to edit it:\n",
    "\n",
    "``` bash\n",
    "# runs on node-eval-online\n",
    "nano eval-online-chi/fastapi_pt/app.py\n",
    "```\n",
    "\n",
    "Near the top of this file, add the new import:\n",
    "\n",
    "``` python\n",
    "from alibi_detect.saving import load_detector\n",
    "```\n",
    "\n",
    "and read in the change detector:\n",
    "\n",
    "``` python\n",
    "# Load the change detector from file\n",
    "cd = load_detector(\"cd\")\n",
    "```\n",
    "\n",
    "then, add the new metrics that we will report to Prometheus -\n",
    "\n",
    "``` python\n",
    "# Counter for drift events\n",
    "drift_event_counter = Counter(\n",
    "        'drift_events_total', \n",
    "        'Total number of drift events detected'\n",
    ")\n",
    "\n",
    "# Histogram for drift test statistic\n",
    "drift_stat_hist = Histogram(\n",
    "        'drift_test_stat', \n",
    "        'Drift score distribution'\n",
    ")\n",
    "```\n",
    "\n",
    "We are going to do drift detection asynchronously - so that the user does not have to wait for the drift detection model before getting the class label.\n",
    "\n",
    "Near the top, add another import:\n",
    "\n",
    "``` python\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "executor = ThreadPoolExecutor(max_workers=2)  # can adjust max_workers as needed\n",
    "```\n",
    "\n",
    "and, right below the definition of the Prometheus metrics, add a drift detection function:\n",
    "\n",
    "``` python\n",
    "def detect_drift_async(cd, x_np):\n",
    "    cd_pred = cd.predict(x_np)\n",
    "    test_stat = cd_pred['data']['test_stat']\n",
    "    is_drift = cd_pred['data']['is_drift']\n",
    "\n",
    "    drift_stat_hist.observe(test_stat)\n",
    "    if is_drift:\n",
    "        drift_event_counter.inc()\n",
    "```\n",
    "\n",
    "Then, in the predict endpoint, right before `return` - add (with the appropriate indentation level)\n",
    "\n",
    "``` python\n",
    "# Submit to async drift detection thread\n",
    "x_np = image.squeeze(0).cpu().numpy()\n",
    "executor.submit(detect_drift_async, cd, x_np)\n",
    "```\n",
    "\n",
    "Save the file with Ctrl+O and Enter, then Ctrl+X to exit.\n",
    "\n",
    "1.  Open the FastAPI `requirements.txt` to edit it:\n",
    "\n",
    "``` bash\n",
    "# runs on node-eval-online\n",
    "nano eval-online-chi/fastapi_pt/requirements.txt\n",
    "```\n",
    "\n",
    "and add\n",
    "\n",
    "    alibi-detect\n",
    "\n",
    "Save the file with Ctrl+O and Enter, then Ctrl+X to exit.\n",
    "\n",
    "1.  Re-build the container image with\n",
    "\n",
    "``` bash\n",
    "# runs on node-eval-online\n",
    "docker compose -f eval-online-chi/docker/docker-compose-prometheus.yaml build fastapi_server\n",
    "```\n",
    "\n",
    "and then recreate it with\n",
    "\n",
    "``` bash\n",
    "# runs on node-eval-online\n",
    "docker compose -f eval-online-chi/docker/docker-compose-prometheus.yaml up -d\n",
    "```\n",
    "\n",
    "Loading the FastAPI service takes a little longer, now that the change detector is part of it - use\n",
    "\n",
    "``` bash\n",
    "# runs on node-eval-online\n",
    "docker logs fastapi_server\n",
    "```\n",
    "\n",
    "until you see\n",
    "\n",
    "    INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Letâ€™s test it! In a browser, weâ€™ll visit\n",
    "\n",
    "    http://A.B.C.D:5000\n",
    "\n",
    "but using the floating IP assigned to our instance in place of `A.B.C.D`. Then, upload a few images to the web app and submit them for classification.\n",
    "\n",
    "Next, open\n",
    "\n",
    "    http://A.B.C.D:8000/docs\n",
    "\n",
    "in a browser, but using the floating IP assigned to our instance. Click on â€œ/metricsâ€, then â€œTry it outâ€ and â€œExecuteâ€. Note that now, the reported metrics include metrics related to drift.\n",
    "\n",
    "To monitor drift live, we can add a Grafana dashboard. In Grafana, click â€œDashboardsâ€ \\> â€œNewâ€ \\> â€œImportâ€ and where it says â€œImport via dashboard JSON modelâ€, paste:\n",
    "\n",
    "    {\n",
    "      \"id\": null,\n",
    "      \"title\": \"Food11 Drift Monitoring\",\n",
    "      \"timezone\": \"browser\",\n",
    "      \"schemaVersion\": 41,\n",
    "      \"version\": 1,\n",
    "      \"refresh\": \"10s\",\n",
    "      \"time\": {\n",
    "        \"from\": \"now-15m\",\n",
    "        \"to\": \"now\"\n",
    "      },\n",
    "      \"panels\": [\n",
    "          {\n",
    "          \"id\": 1,\n",
    "          \"type\": \"stat\",\n",
    "          \"title\": \"Drift Events (per second)\",\n",
    "          \"datasource\": \"prometheus\",\n",
    "          \"gridPos\": { \"x\": 0, \"y\": 0, \"w\": 12, \"h\": 8 },\n",
    "          \"targets\": [\n",
    "            {\n",
    "              \"expr\": \"rate(drift_events_total[1m])\",\n",
    "              \"refId\": \"A\"\n",
    "            }\n",
    "          ],\n",
    "          \"options\": {\n",
    "            \"reduceOptions\": {\n",
    "              \"calcs\": [\"lastNotNull\"],\n",
    "              \"fields\": \"\",\n",
    "              \"values\": false\n",
    "            },\n",
    "            \"orientation\": \"horizontal\",\n",
    "            \"colorMode\": \"value\",\n",
    "            \"graphMode\": \"area\",         \n",
    "            \"textMode\": \"auto\"\n",
    "          },\n",
    "          \"fieldConfig\": {\n",
    "            \"defaults\": {\n",
    "              \"unit\": \"ops\",\n",
    "              \"decimals\": 2,\n",
    "              \"thresholds\": {\n",
    "                \"mode\": \"absolute\",\n",
    "                \"steps\": [\n",
    "                  { \"color\": \"green\", \"value\": null },\n",
    "                  { \"color\": \"red\", \"value\": 1 }\n",
    "                ]\n",
    "              }\n",
    "            },\n",
    "            \"overrides\": []\n",
    "          }\n",
    "        },\n",
    "        {\n",
    "          \"id\": 2,\n",
    "          \"type\": \"timeseries\",\n",
    "          \"title\": \"Median Drift Score (test_stat)\",\n",
    "          \"datasource\": \"prometheus\",\n",
    "          \"gridPos\": { \"x\": 12, \"y\": 0, \"w\": 12, \"h\": 8 },\n",
    "          \"targets\": [\n",
    "            {\n",
    "              \"expr\": \"histogram_quantile(0.5, rate(drift_test_stat_bucket[1m]))\",\n",
    "              \"refId\": \"A\",\n",
    "              \"legendFormat\": \"median test_stat\"\n",
    "            }\n",
    "          ],\n",
    "          \"options\": {\n",
    "            \"legend\": {\n",
    "              \"displayMode\": \"list\",\n",
    "              \"placement\": \"bottom\"\n",
    "            },\n",
    "            \"tooltip\": {\n",
    "              \"mode\": \"single\"\n",
    "            }\n",
    "          },\n",
    "          \"fieldConfig\": {\n",
    "            \"defaults\": {\n",
    "              \"unit\": \"none\",\n",
    "              \"decimals\": 4\n",
    "            },\n",
    "            \"overrides\": []\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "\n",
    "Then click â€œLoadâ€ and â€œImportâ€."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see it in action, letâ€™s generate some requests from Food11:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs in jupyter container on node-eval-online\n",
    "food_11_data_dir = os.getenv(\"FOOD11_DATA_DIR\", \"Food-11\")\n",
    "test_dataset = datasets.ImageFolder(root=os.path.join(food_11_data_dir, 'evaluation'))\n",
    "image_paths = [sample[0] for sample in test_dataset.samples]\n",
    "random.shuffle(image_paths)\n",
    "\n",
    "FASTAPI_URL = \"http://fastapi_server:8000/predict\"\n",
    "\n",
    "for image_path in image_paths:\n",
    "    with open(image_path, 'rb') as f:\n",
    "        image_bytes = f.read()\n",
    "    encoded_str = base64.b64encode(image_bytes).decode(\"utf-8\")\n",
    "    payload = {\"image\": encoded_str}\n",
    "    response = requests.post(FASTAPI_URL, json=payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then some requests from the AI samples that are *not* similar to the Food11 data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs in jupyter container on node-eval-online\n",
    "image_dir = \"ai_images\"\n",
    "image_paths = [\n",
    "    os.path.join(image_dir, fname)\n",
    "    for fname in os.listdir(image_dir)\n",
    "    if fname.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
    "]\n",
    "\n",
    "FASTAPI_URL = \"http://fastapi_server:8000/predict\"\n",
    "\n",
    "for _ in range(1000):\n",
    "    random.shuffle(image_paths)\n",
    "    for image_path in image_paths:\n",
    "        with open(image_path, 'rb') as f:\n",
    "            image_bytes = f.read()\n",
    "        encoded_str = base64.b64encode(image_bytes).decode(\"utf-8\")\n",
    "        payload = {\"image\": encoded_str}\n",
    "        response = requests.post(FASTAPI_URL, json=payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it is done, take a screenshot of the â€œFood11 Drift Monitoringâ€ dashboard for later reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------\n",
    "\n",
    "When you have finished with this section, bring down these services with\n",
    "\n",
    "``` bash\n",
    "# runs on node-eval-online\n",
    "docker compose -f eval-online-chi/docker/docker-compose-prometheus.yaml up -d\n",
    "```"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 4,
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": "3"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python"
  }
 }
}
